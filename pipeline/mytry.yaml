apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: try-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline_compilation_time: '2021-07-15T10:37:09.293095',
    pipelines.kubeflow.org/pipeline_spec: '{"name": "try"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4}
spec:
  entrypoint: try
  templates:
  - name: read
    container:
      args: [--output-text, /tmp/outputs/output_text/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def read(output_text_path):
            from sshtunnel import SSHTunnelForwarder
            import pymysql
            import pandas as pd
            import numpy as np
            f=open(output_text_path,'w');
            server=SSHTunnelForwarder(('47.92.240.36', 22),  ssh_username='jt',  ssh_password='vdaubCp7yaSreqlT', remote_bind_address=('192.168.0.84', 3306))
            server.start()
            conn = pymysql.connect(host='127.0.0.1',  port=server.local_bind_port,user='root',  passwd='root' , charset ='utf8',   database = 'dump',)
            sql_get_total = f"select title from ms_paper_ghl_20201026"
            df = pd.read_sql(sql_get_total, con=conn)
            df.to_csv(output_text_path,index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Read', description='')
        _parser.add_argument("--output-text", dest="output_text_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = read(**_parsed_args)
      image: star16231108/python:3.7
    outputs:
      artifacts:
      - {name: read-output_text, path: /tmp/outputs/output_text/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--output-text", {"outputPath": "output_text"}], "command": ["sh",
          "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef read(output_text_path):\n    from sshtunnel import SSHTunnelForwarder\n    import
          pymysql\n    import pandas as pd\n    import numpy as np\n    f=open(output_text_path,''w'');\n    server=SSHTunnelForwarder((''47.92.240.36'',
          22),  ssh_username=''jt'',  ssh_password=''vdaubCp7yaSreqlT'', remote_bind_address=(''192.168.0.84'',
          3306))\n    server.start()\n    conn = pymysql.connect(host=''127.0.0.1'',  port=server.local_bind_port,user=''root'',  passwd=''root''
          , charset =''utf8'',   database = ''dump'',)\n    sql_get_total = f\"select
          title from ms_paper_ghl_20201026\"\n    df = pd.read_sql(sql_get_total,
          con=conn)\n    df.to_csv(output_text_path,index=False)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Read'', description='''')\n_parser.add_argument(\"--output-text\",
          dest=\"output_text_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = read(**_parsed_args)\n"], "image": "star16231108/python:3.7"}}, "name":
          "Read", "outputs": [{"name": "output_text"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "1306fc6174aa0e6a9cb6464710dd1e66e09207925559f55d8a82ecbaf5639e70", "url":
          "../components/read.yaml"}'}
  - name: tag
    container:
      args: [--text, /tmp/inputs/text/data, --output-text, /tmp/outputs/output_text/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def tag(text_path,output_text_path):
            import numpy as np
            import pandas as pd
            data=pd.read_csv(text_path)
            data=data[0:1]
            data.to_csv(output_text_path,index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Tag', description='')
        _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--output-text", dest="output_text_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = tag(**_parsed_args)
      image: star16231108/python:3.7
    inputs:
      artifacts:
      - {name: trans-output_text, path: /tmp/inputs/text/data}
    outputs:
      artifacts:
      - {name: tag-output_text, path: /tmp/outputs/output_text/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--text", {"inputPath": "text"}, "--output-text", {"outputPath":
          "output_text"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path),
          exist_ok=True)\n    return file_path\n\ndef tag(text_path,output_text_path):\n    import
          numpy as np\n    import pandas as pd\n    data=pd.read_csv(text_path)\n    data=data[0:1]\n    data.to_csv(output_text_path,index=False)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Tag'', description='''')\n_parser.add_argument(\"--text\",
          dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-text\",
          dest=\"output_text_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = tag(**_parsed_args)\n"], "image": "star16231108/python:3.7"}}, "inputs":
          [{"name": "text"}], "name": "Tag", "outputs": [{"name": "output_text"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "338c6526b24e4dcd874f841a25a3ac4d9b7786ff462b7c8a100ec8ba22e49e7d",
          "url": "../components/tag.yaml"}'}
  - name: trans
    container:
      args: [--text, /tmp/inputs/text/data, --output-text, /tmp/outputs/output_text/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def trans(text_path,output_text_path):
            import numpy as np
            import pandas as pd
            data=pd.read_csv(text_path)
            data=data[-2:]
            data.to_csv(output_text_path,index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Trans', description='')
        _parser.add_argument("--text", dest="text_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--output-text", dest="output_text_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = trans(**_parsed_args)
      image: star16231108/python:3.7
    inputs:
      artifacts:
      - {name: read-output_text, path: /tmp/inputs/text/data}
    outputs:
      artifacts:
      - {name: trans-output_text, path: /tmp/outputs/output_text/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--text", {"inputPath": "text"}, "--output-text", {"outputPath":
          "output_text"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path),
          exist_ok=True)\n    return file_path\n\ndef trans(text_path,output_text_path):\n    import
          numpy as np\n    import pandas as pd\n    data=pd.read_csv(text_path)\n    data=data[-2:]\n    data.to_csv(output_text_path,index=False)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Trans'', description='''')\n_parser.add_argument(\"--text\",
          dest=\"text_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-text\",
          dest=\"output_text_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = trans(**_parsed_args)\n"], "image": "star16231108/python:3.7"}}, "inputs":
          [{"name": "text"}], "name": "Trans", "outputs": [{"name": "output_text"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "645fe04c1102aec1f24035c6a52bb23b9cd89f38fc7ccab23531e6bd6e7df5b8",
          "url": "../components/trans.yaml"}'}
  - name: try
    dag:
      tasks:
      - {name: read, template: read}
      - name: tag
        template: tag
        dependencies: [trans]
        arguments:
          artifacts:
          - {name: trans-output_text, from: '{{tasks.trans.outputs.artifacts.trans-output_text}}'}
      - name: trans
        template: trans
        dependencies: [read]
        arguments:
          artifacts:
          - {name: read-output_text, from: '{{tasks.read.outputs.artifacts.read-output_text}}'}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
